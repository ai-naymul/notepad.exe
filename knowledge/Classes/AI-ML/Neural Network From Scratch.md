
1. what is sigmoid function? Tanh? Relu? modern variants like gelu etc.??
2. why we do square error?(mse)
3. gradient descent?
4. what is the need of activision func?
5. what is 42 and why is 42 in ml?


Play around: https://colab.research.google.com/drive/1OuJA1KC2IUexv0TXGkkQTTl1B-kJKV-P?usp=sharing



